experiment:
  name: "distilbert_base_regularized_experiment"
  description: "DistilBERT Base with regularization to prevent overfitting"
  seed: 42

model:
  type: "distilbert"
  name: "distilbert-base-uncased"
  num_labels: 3
  dropout_prob: 0.3

data:
  train_path: "dataset/train"
  eval_path: "dataset/test/SemEval2017-task4-test.subtask-A.english.txt"
  max_length: 128

training:
  batch_size: 16
  learning_rate: 1e-5
  weight_decay: 0.08
  num_epochs: 10
  warmup_proportion: 0.1
  max_grad_norm: 1.0
  early_stopping:
    patience: 3
    min_delta: 0.0005

output:
  output_dir: "experiments/distilbert_base_regularized"
  save_best_only: true